{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_folder(code):\n",
    "    file_path = f\"{code}/CURATION_USER.tsv\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find main line starting with \"#Text=\"\n",
    "    main_line = next(line for line in lines if line.startswith(\"#Text=\"))\n",
    "\n",
    "    # Split main line with semicolon\n",
    "    origin_split_semicolon = main_line.strip()[6:].split(\";\")\n",
    "\n",
    "    # Find all lines starting with \"1-\"\n",
    "    queue_line_top_down = [line for line in lines if line.startswith(\"1-\")]\n",
    "\n",
    "    # Create pairs of first element of semicolon-split element and next L lines from queue_line_top_down\n",
    "    result = []\n",
    "    result_dict = {}\n",
    "\n",
    "    for element in origin_split_semicolon:\n",
    "        \n",
    "        L = len(element.split())\n",
    "        # pair = (element, [queue_line_top_down.pop(0) for i in range(L)])\n",
    "        # result.append(pair)\n",
    "        result_dict[element] = [queue_line_top_down.pop(0) for i in range(L)]\n",
    "\n",
    "\n",
    "    # return result\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_folder_keep_first(folder_path, output_folder,n=10):\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    new_folder_prefix = folder_name[:-6]\n",
    "    print(\"new_folder_prefix \", new_folder_prefix)\n",
    "    with open(os.path.join(folder_path, 'CURATION_USER.tsv'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].startswith(\"#Text=\"):\n",
    "                texts = lines[i].strip().split(';')\n",
    "                first_text = texts[0][6:]\n",
    "                print(\"first_text \", first_text)\n",
    "                remaining_texts = texts[1:]\n",
    "                new_texts = [first_text + ';' + ';'.join(remaining_texts[j:j+n]) \n",
    "                             for j in range(0, len(remaining_texts), n)]\n",
    "\n",
    "                # print(\"first_text \", remaining_texts)\n",
    "                for j in range(len(new_texts)):\n",
    "                    new_folder_name = '{:03d}0'.format(j+1) + folder_name[4:]\n",
    "                    new_folder_path = os.path.join(os.path.dirname(output_folder), new_folder_name)\n",
    "                    if not os.path.exists(new_folder_path):\n",
    "                        os.mkdir(new_folder_path)\n",
    "                    new_file_path = os.path.join(new_folder_path, 'CURATION_USER.tsv')\n",
    "                    print(new_file_path)\n",
    "                    with open(new_file_path, 'w') as new_file:\n",
    "                        new_texts_j = new_texts[j].split(\";\")\n",
    "                        line_1_n = \"\"\n",
    "                        for e in new_texts_j:\n",
    "                            line_1_n += \"\".join(result_dict[e])\n",
    "\n",
    "                        new_texts_j_final = new_texts[j].replace(\";\",\".\")\n",
    "                        new_lines = lines[:i] + ['#Text=' + new_texts_j_final + '\\n'+line_1_n]\n",
    "                        new_file.writelines(new_lines)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_folder_dot(code):\n",
    "    file_path = f\"{code}/CURATION_USER.tsv\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find main line starting with \"#Text=\"\n",
    "    main_line = next(line for line in lines if line.startswith(\"#Text=\"))\n",
    "\n",
    "    # Split main line with semicolon\n",
    "    origin_split_semicolon = main_line.strip().split(\". \")\n",
    "\n",
    "    # Find all lines starting with \"1-\"\n",
    "    queue_line_top_down = [line for line in lines if line.startswith(\"1-\")]\n",
    "\n",
    "    # Create pairs of first element of semicolon-split element and next L lines from queue_line_top_down\n",
    "    result = []\n",
    "    result_dict = {}\n",
    "\n",
    "    for element in origin_split_semicolon:\n",
    "        \n",
    "        L = len(element.split())\n",
    "        # pair = (element, [queue_line_top_down.pop(0) for i in range(L)])\n",
    "        # result.append(pair)\n",
    "        result_dict[element] = [queue_line_top_down.pop(0) for i in range(L)]\n",
    "\n",
    "\n",
    "    # return result\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "def process_folder(folder_path, output_folder,n=10):\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    new_folder_prefix = folder_name[:-6]\n",
    "    print(\"new_folder_prefix \", new_folder_prefix)\n",
    "    with open(os.path.join(folder_path, 'CURATION_USER.tsv'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].startswith(\"#Text=\"):\n",
    "                texts = lines[i].strip().split('. ')\n",
    "                # first_text = texts[0][6:]\n",
    "                # print(\"first_text \", first_text)\n",
    "                remaining_texts = texts\n",
    "                new_texts = ['. '.join(remaining_texts[j:j+n]) \n",
    "                             for j in range(0, len(remaining_texts), n)]\n",
    "\n",
    "                # print(\"first_text \", remaining_texts)\n",
    "                for j in range(len(new_texts)):\n",
    "                    new_folder_name = '1{:03d}'.format(j+1) + folder_name[4:]\n",
    "                    new_folder_path = os.path.join(os.path.dirname(output_folder), new_folder_name)\n",
    "                    if not os.path.exists(new_folder_path):\n",
    "                        os.mkdir(new_folder_path)\n",
    "                    new_file_path = os.path.join(new_folder_path, 'CURATION_USER.tsv')\n",
    "                    print(new_file_path)\n",
    "                    with open(new_file_path, 'w') as new_file:\n",
    "                        new_texts_j = new_texts[j].split(\". \")\n",
    "                        line_1_n = \"\"\n",
    "                        for e in new_texts_j:\n",
    "                            line_1_n += \"\".join(result_dict_dot[e])\n",
    "\n",
    "                        new_texts_j_final = new_texts[j]\n",
    "                        new_lines = lines[:i] + ['#Text=' + new_texts_j_final + '\\n'+line_1_n]\n",
    "                        new_file.writelines(new_lines)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_file_folder_path = \\\n",
    "#     \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/23355290.conll\"\n",
    "# result_dict = read_conll_folder(big_file_folder_path)\n",
    "\n",
    "# new_splited_output_folder = \\\n",
    "#  \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/output_split_BIG_file/new/\"\n",
    "\n",
    "# numer_sent = 7\n",
    "# process_folder_keep_first(big_file_folder_path, new_splited_output_folder, numer_sent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_folder_prefix  23354880\n",
      "/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/output_split_BIG_file/new/10014880.conll/CURATION_USER.tsv\n",
      "/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/output_split_BIG_file/new/10024880.conll/CURATION_USER.tsv\n",
      "/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/output_split_BIG_file/new/10034880.conll/CURATION_USER.tsv\n",
      ">>> need check & MANUALLY edit again\n"
     ]
    }
   ],
   "source": [
    "big_file_folder_path = \\\n",
    "    \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/23354880.conll\"\n",
    "\n",
    "new_splited_output_folder = \\\n",
    " \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/example_VLSP_big_size/output_split_BIG_file/new/\"\n",
    "\n",
    "result_dict_dot = read_conll_folder_dot(big_file_folder_path)\n",
    "\n",
    "numer_sent = 12\n",
    "process_folder(big_file_folder_path, new_splited_output_folder, numer_sent )\n",
    "\n",
    "print(\">>> need check & MANUALLY edit again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/VLSP2020_RE_dev/23354880.conll removed successfully.\n",
      "/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/VLSP2020_RE_dev/23355290.conll removed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \\\n",
    "'/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/VLSP2020_RE_dev/23354880.conll'\n",
    "\n",
    "folder_path_2 = \\\n",
    "'/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/VLSP2020_RE_dev/23355290.conll'\n",
    "\n",
    "def remove_old_folder_code_on_raw(folder_path):\n",
    "    try:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isdir(file_path):\n",
    "                os.rmdir(file_path)\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "        os.rmdir(folder_path)\n",
    "        print(f\"{folder_path} removed successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {folder_path} : {e.strerror}\")\n",
    "\n",
    "remove_old_folder_code_on_raw(folder_path)\n",
    "remove_old_folder_code_on_raw(folder_path_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reEnv3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
