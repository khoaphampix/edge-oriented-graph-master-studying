{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import json\n",
        "from os import listdir, remove\n",
        "from os.path import isfile, join, isdir\n",
        "\n",
        "def write_append_data_to_txt_file(full_path_to_file, txt):\n",
        "    with open(full_path_to_file,'a') as out:\n",
        "        out.write(f'{txt}\\n')\n",
        "        # out.write(f'{txt}')s\n",
        "        \n",
        "def clear_file(full_path_to_files_list):\n",
        "    for _file in full_path_to_files_list:\n",
        "      with open(_file,'w') as out:\n",
        "        out.write(f'')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "['’', '¾', '²', '.', '>', '+', '/', '|', '\\n', ',', '‘', \n",
        "\n",
        "'&', \"'\", '*', '-', '\"', ']', '?', ':', '“', '\\t', ';', '–', \n",
        "\n",
        "'½', '_', '\\ufeff', '…', '!', '(', ' ', '@', '”', '[', '=', '%', ')']\n",
        "\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
        "\n",
        "['.', '>', '+', '/', ',', '&', \"'\", '*', '-', '\"', ']', '?', ':', ';', '!', '(', ')' '@', \"[\", '=', '%', ']'\n",
        ".>+/&,*-?:;!()@[,=%]\"'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"100 . 00 to 100.00, or 50 . 1 to 501 but 31 . n will keep 31 . n\"\n",
        "pattern = r\"(\\d+)\\s*\\.\\s*(\\d+)\"\n",
        "replacement = r\"\\1\\2\"\n",
        "result = re.sub(pattern, replacement, text)\n",
        "\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def case_dot_number(text):\n",
        "    # text = \"100 . 00 to 100.00, or 50 . 1 to 501 but 31 . n will keep 31 . n\"\n",
        "    pattern = r\"(\\d+)\\s*\\.\\s*(\\d+)\"\n",
        "    replacement = r\"\\1\\2\"\n",
        "    result = re.sub(pattern, replacement, text)\n",
        "    return result\n",
        "\n",
        "def remove_char_dot_etc__and_word(sent):\n",
        "    # Define the regular expression pattern for splitting\n",
        "    # pattern = r\"\"\"([.,-])\"\"\" # origin\n",
        "    # pattern = r\"\"\"([.>+/&,*\\-?:;!()@\\[\\]=%\\\"'])\"\"\"\n",
        "    pattern = r\"\"\"([>+/&*\\:;()@\\[\\]=%\\\"'])\"\"\"\n",
        "    # Split the input string based on the pattern and add spaces around the punctuation marks\n",
        "\n",
        "    # output_str = re.sub(pattern, r\"\", sent).replace(\" . . . \",\" \")\n",
        "    # output_str = case_dot_number(output_str).replace(\" . \",\" \")\n",
        "    # output_str = output_str.replace(\" - \",\" \")\n",
        "    # output_str = output_str.replace(\"  \",\" \")\n",
        "\n",
        "    output_str = re.sub(pattern, r\"\", sent).replace(\"...\",\"\")\n",
        "    # output_str = case_dot_number(output_str).replace(\".\",\" \")\n",
        "    # output_str = output_str.replace(\" - \",\" \")\n",
        "    # output_str = output_str.replace(\" . \",\"\")\n",
        "    output_str = output_str.replace(\"  \",\" \")\n",
        "\n",
        "\n",
        "    regex = r\"\\d+\\s+\\.\\s+\\d+\"\n",
        "    matches = re.findall(regex, output_str)\n",
        "    # print(output_str)\n",
        "    # print(matches)\n",
        "    if matches:\n",
        "        # print(output_str)\n",
        "        for match in matches:\n",
        "            print(output_str[:10], \"<>\", match) \n",
        "            new_match = match.replace(\" . \",\".\")\n",
        "            output_str = output_str.replace(match, new_match)\n",
        "        print(output_str, \"\\n\")\n",
        "\n",
        "\n",
        "    regex = r\"\\d+\\s+\\,\\s+\\d+\"\n",
        "    matches = re.findall(regex, output_str)\n",
        "    # print(output_str)\n",
        "    # print(matches)\n",
        "    if matches:\n",
        "        # print(output_str)\n",
        "        for match in matches:\n",
        "            print(output_str[:10], \"<>\", match) \n",
        "            new_match = match.replace(\" , \",\",\")\n",
        "            output_str = output_str.replace(match, new_match)\n",
        "        print(output_str, \"\\n\")\n",
        "\n",
        "\n",
        "    return output_str\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_str = \"\"\"Tới nay , đã HN . TP có hơn 100 . 000 % hành_khách TP - Singapore đăng_ký tham_gia chương_trình thí_điểm , với số lượt thanh_toán mỗi ngày đạt trên 60 . 000 \"\"\"\n",
        "output_str = remove_char_dot_etc__and_word(input_str)\n",
        "# Print the output string\n",
        "print(input_str)\n",
        "print(len(output_str[:20]))\n",
        "print(output_str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import listdir, remove\n",
        "from os.path import isfile, join, isdir\n",
        "from pprint import pprint\n",
        "\n",
        "special_split_sent_not_final_IN_path_folder = \\\n",
        "\"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/split_sentence_underthesea/docs/common_info_embedd_files/split_passage_for_final_processed\"\n",
        "\n",
        "# clear_file([shortEnt_in_longEntity_OUT_PATH])\n",
        "\n",
        "\n",
        "onlyfiles = [f for f in listdir(special_split_sent_not_final_IN_path_folder) if isfile(join(special_split_sent_not_final_IN_path_folder, f))]\n",
        "onlyfiles = sorted(onlyfiles)\n",
        "print(onlyfiles)\n",
        "\n",
        "count_abnomal = 0\n",
        "for idx, doc_code in enumerate(onlyfiles):\n",
        "\n",
        "    \n",
        "    # if idx > 1:\n",
        "    #     break\n",
        "    # print(doc_code)\n",
        "    special_split_sent_not_final_IN_path = special_split_sent_not_final_IN_path_folder+'/'+ doc_code\n",
        "    with open(special_split_sent_not_final_IN_path,'r') as _org_docs_file:\n",
        "        doc_list = []\n",
        "        for org_docs_line in _org_docs_file:\n",
        "            org_docs_line = org_docs_line[:-1]\n",
        "            word_after_code =  org_docs_line[8:11]\n",
        "\n",
        "            if  word_after_code == '|a|':\n",
        "                not_sent = org_docs_line[:11]\n",
        "                list_sent = org_docs_line[11:]\n",
        "                # print(not_sent)\n",
        "                # print(list_sent)\n",
        "                list_sent = list_sent.split(\".|\")\n",
        "                list_sent = [remove_char_dot_etc__and_word(s) for s in list_sent] \n",
        "                list_sent = \".|\".join(list_sent)\n",
        "                # print(list_sent)\n",
        "                # SPECIAL_HARD_CODE = \" . \"\n",
        "                SPECIAL_HARD_CODE = \"\"\n",
        "                org_docs_line = not_sent + list_sent+SPECIAL_HARD_CODE\n",
        "            elif len(org_docs_line.split('\\t')) ==6:\n",
        "                org_docs_line = remove_char_dot_etc__and_word(org_docs_line)\n",
        "\n",
        "\n",
        "\n",
        "#             doc_list.append(org_docs_line)\n",
        "\n",
        "#         file_name = special_split_sent_not_final_IN_path_folder+\"/\"+doc_code\n",
        "#         clear_file([file_name])        \n",
        "#         for line_to_write in doc_list:\n",
        "#             write_append_data_to_txt_file(file_name, line_to_write)\n",
        "# print(f\"count_abnomal:  {count_abnomal}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### START TO CREATE PROCESSED FILE\n",
        "# sample:\n",
        "625456\tObsolete ... preparations .|One case ... years .|\n",
        "\n",
        "1:CID:2\tR2L\tNON-CROSS\t27-31\t10-11\t\n",
        "    D002119\tcalcium carbon - ate\tChemical\t27\t31\t1\t\n",
        "    D006934\thypercalcaemia\tDisease\t10\t11\t1\t\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
