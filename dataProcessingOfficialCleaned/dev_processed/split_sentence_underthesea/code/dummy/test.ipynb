{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# line = \"\"\"7 nguyên nhân khiến Real Madrid bị Barcelona bỏ xa tại La Liga Tờ Marca của Tây Ban Nha đã chỉ ra những yếu tố lý giải cho sự khởi đầu tệ hại của Real Madrid tại La Liga 2017/2018. Gặp vấn đề trong khâu ghi bàn: Việc cả đội Real Madrid chỉ ghi được tổng số bàn bằng với Lionel Messi (9 bàn) cho thấy 2 điều: Messi đã sẵn sàng cho việc xé lưới các đối thủ, trong khi Real thì không. Trong trận gặp Betis mới đây, Real cũng bị đứt chuỗi ghi bàn liên tiếp trong 73 trận dù sút tới 27 lần, và có Ronaldo trở lại. Bầu không khí tại Bernabeu : Sau trận thua Betis , tiền vệ Isco nói rằng: \"Nếu chúng tôi không thể ghi bàn thắng sớm tại Bernabeu thì sự hoang mang bắt đầu xâm chiếm\". Điều này cho thấy các học trò của Zidane luôn phải chịu một áp lực không nhỏ khi thi đấu tại chính sân nhà của mình. Cổ động viên Real luôn đòi hỏi cao ở đội bóng và sẵn sàng la ó dù cầu thủ chơi tốt. Những quyết định của Zidane : Ở trận gặp Real Betis , Zidane đã có một quyết định khó hiểu khi để Asensio đá chính thay vì Isco , dù số 22 đang có phong độ rất cao. Thậm chí, ông còn rút ra Luka Modric khi trận đấu vẫn còn 20 phút nữa. Còn nhớ ở trận gặp Levante , Zidane cũng thực hiện chính sách xoay tua và tung ra 1 đội hình khá khó hiểu. Phản ứng trọng tài: Sau lệnh cấm thi đấu 5 trận của Cristiano Ronaldo , có vẻ như các cầu thủ Real đã quá chú ý vào việc phản ứng trọng tài hơn là tập trung chuyên môn. Điều này làm trận đấu với Betis trở nên căng thẳng trên mức cần thiết. Chấn thương: Mới đây, hậu vệ Marcelo đã dính chấn thương nhưng trước đó, Real đã mất Theo Hernandez , Karim Benzema , Mateo Kovacic , Jesus Vallejo và Raphael Varane cũng vì lý do tương tự. Không có lực lượng mạnh nhất, việc Real đánh rơi điểm là điều dễ hiểu. Hiệu ứng Siêu cúp Tây Ban Nha : Với việc hạ Barcelona tại Siêu cúp Tây Ban Nha sau 2 lượt trận với tổng tỷ số 5-1, có vẻ như các cầu thủ Real đã có dấu hiệu tự mãn. Nhiều cái tên đã không thể chơi đúng với khả năng của mình trong suốt 1 tháng qua. Thói quen để thủng lưới: Chỉ sau 5 trận đấu, thủ thành Keylor Navas đã để thủng lưới tới 5 bàn. Đến những đội bóng nhỏ như Levante , Betis hay Real Sociedad cũng có thể xuyên thủng mảnh lưới Real Madrid . Hòa Lộc\"\"\"\n",
        "# line_ls =[line]\n",
        "\n",
        "# # line_ls = [\n",
        "# # \"Bị tàu_hỏa tông trực_diện, người đàn_ông tử_vong tại_chỗ Băng qua đường tàu, nạn_nhân Lê_Quý_D. , trú huyện Đức_Thọ , tỉnh Hà_Tĩnh đã bị tàu SE6 tông trực_diện, tử_vong tại_chỗ. Tối 22/9, thượng_tá Nguyễn_Duy_Đông , Trưởng Công_an huyện Đức_Thọ , tỉnh Hà_Tĩnh thông_tin, trên địa_bàn vừa xảy ra vụ tai_nạn đường_sắt khiến 1 nạn_nhân tử_vong. Ảnh minh_họa. Theo đó, vào_khoảng 12h50 cùng ngày, tàu SE6 chạy theo hướng Nam - Bắc, khi đến Km344+850 gần ga Đức_Lạc , thuộc huyện này thì xảy ra va_chạm với anh Lê_Quý_D. (SN 1972), trú tại thôn Hòa_Thái , xã Đức_Lạc . Cú tông trực_diện đã khiến nạn_nhân tử_vong tại_chỗ. Theo một_số người_dân có_mặt tại hiện_trường cho_biết, thời_điểm xảy ra vụ_việc, nạn_nhân đã tự_ý đi băng qua đường tàu. Hiện, nguyên_nhân vụ tai_nạn đang được Công_an huyện Đức_Thọ điều_tra, làm rõ.\"\n",
        "# # ,\n",
        "# # \"Bị tàu hỏa tông trực diện, người đàn ông tử vong tại chỗ Băng qua đường tàu, nạn nhân Lê Quý D. , trú huyện Đức Thọ , tỉnh Hà Tĩnh đã bị tàu SE6 tông trực diện, tử vong tại chỗ. Tối 22/9, thượng tá Nguyễn Duy Đông , Trưởng Công an huyện Đức Thọ , tỉnh Hà Tĩnh thông tin, trên địa bàn vừa xảy ra vụ tai nạn đường sắt khiến 1 nạn nhân tử vong. Ảnh minh họa. Theo đó, vào khoảng 12h50 cùng ngày, tàu SE6 chạy theo hướng Nam - Bắc, khi đến Km344+850 gần ga Đức Lạc , thuộc huyện này thì xảy ra va chạm với anh Lê Quý D. (SN 1972), trú tại thôn Hòa Thái , xã Đức Lạc . Cú tông trực diện đã khiến nạn nhân tử vong tại chỗ. Theo một số người dân có mặt tại hiện trường cho biết, thời điểm xảy ra vụ việc, nạn nhân đã tự ý đi băng qua đường tàu. Hiện, nguyên nhân vụ tai nạn đang được Công an huyện Đức Thọ điều tra, làm rõ.\"\n",
        "# # ]\n",
        "\n",
        "# from underthesea import sent_tokenize, word_tokenize\n",
        "\n",
        "# for line in line_ls:\n",
        "#     print(\"- \"*40)\n",
        "#     sentence_list = sent_tokenize(line)\n",
        "#     # print(sentence_list)\n",
        "#     for s in sentence_list:\n",
        "#         # print(s)\n",
        "#         word_tokenize_ls = word_tokenize(s, format=\"text\").split(\" \")\n",
        "#         # print(word_tokenize_ls)\n",
        "#         for w in word_tokenize_ls:\n",
        "#             if \"_\" in w:\n",
        "#                 print(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# INPUT: \n",
        "#     - all docs, 1 paragraph - 1 line (filter (no-relation) raw data without any processing like: remove dot, quote ...)\n",
        "#     - All_sentence.PubTator.txt\n",
        "    \n",
        "# OUTPUT: \n",
        "#     - all docs, 1 paragraph - with splited sentences with struct: <code><$$##$$$$##$$><sent><$$##$$$$##$$><sent>\n",
        "#     - saved to <split_sentence_from_paragraph.txt>\n",
        "    \n",
        "# # HOW \n",
        "# split to sentence smartly by underthesea (recognize 20.10, TP.HCM ...)\n",
        "# replace \\xa0 (bug by text after processed by underthesea)\n",
        "\n",
        "# \"\"\"\n",
        "# file_name = \\\n",
        "#     \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/split_sentence_underthesea/docs/common_info_embedd_files/CDR_DevelopmentSet.PubTator.txt\"\n",
        "\n",
        "# from underthesea import sent_tokenize, word_tokenize\n",
        "\n",
        "# def split_sentence_from_paragraph(filename):\n",
        "\n",
        "#     stop_line = 9999\n",
        "#     current_line = 0\n",
        "#     # clear_file(out_put)\n",
        "#     # clear_file(out_put_with_token)\n",
        "\n",
        "#     with open(filename, \"r\") as file:\n",
        "#         n = 1\n",
        "#         for line in file:\n",
        "#             current_line+=1\n",
        "#             if current_line > stop_line:\n",
        "#                 break\n",
        "            \n",
        "#             # print(line)\n",
        "#             code_ = line[0:8]\n",
        "#             # print(code_)\n",
        "#             # print(\"code_ \", code_)\n",
        "#             if line[8:11] == '|a|':\n",
        "#                 if n > 2: break\n",
        "#                 n+=1\n",
        "#                 # print(line[11:] )\n",
        "#                 line = line[11:]\n",
        "#                 sentence_list = sent_tokenize(line)\n",
        "#                 # print(sentence_list)\n",
        "#                 for s in sentence_list:\n",
        "#                     print(s)\n",
        "#                     word_tokenize_ls = word_tokenize(s, format=\"text\").split(\" \")\n",
        "#                     # print(word_tokenize_ls)\n",
        "#                     for w in word_tokenize_ls:\n",
        "#                         if \"_\" in w:\n",
        "#                             print(w)\n",
        "\n",
        "# split_sentence_from_paragraph(file_name)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ls = ['Bị tàu hỏa tông trực diện, người đàn ông tử vong tại chỗ Băng qua đường tàu, nạn nhân Lê Quý D. , trú huyện Đức Thọ , tỉnh Hà Tĩnh đã bị tàu SE6 tông trực diện, tử vong tại chỗ.', 'Tối 22/9, thượng tá Nguyễn Duy Đông , Trưởng Công an huyện Đức Thọ , tỉnh Hà Tĩnh thông tin, trên địa bàn vừa xảy ra vụ tai nạn đường sắt khiến 1 nạn nhân tử vong.', 'Ảnh minh họa.', 'Theo đó, vào khoảng 12h50 cùng ngày,\\xa0tàu\\xa0SE6 chạy theo hướng Nam - Bắc, khi đến Km344+850 gần ga Đức Lạc , thuộc huyện này thì xảy ra va chạm với anh Lê Quý D. (SN 1972), trú tại thôn Hòa Thái , xã Đức Lạc .', 'Cú tông trực diện đã khiến nạn nhân tử vong tại chỗ.', 'Theo một số người dân có mặt tại hiện trường cho biết, thời điểm xảy ra vụ việc, nạn nhân đã tự ý đi băng qua đường tàu.', 'Hiện, nguyên nhân vụ tai nạn đang được Công an huyện Đức Thọ điều tra, làm rõ.']\n",
        "\n",
        "# ls_str = \"|\".join(ls)\n",
        "# print(ls_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_dict_ents = \\\n",
        "# {\n",
        "#     '2335248900008': {\n",
        "#         'data': [[5, 6, 0, 'ORGANIZATION'],\n",
        "#         [320, 321, 13, 'ORGANIZATION']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Barcelona', 'Barcelona']\n",
        "#     },\n",
        "#     '2335248900015': {\n",
        "#         'data': [[10, 11, 0, 'ORGANIZATION']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Marca']\n",
        "#     },\n",
        "#     '2335248900061': {\n",
        "#         'data': [[46, 47, 1, 'PERSON'], [52, 53, 1, 'PERSON']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Lionel_Messi', 'Messi']\n",
        "#     },\n",
        "#     '2335248900117': {\n",
        "#         'data': [[94, 95, 3, 'LOCATION'], [112, 113, 3, 'LOCATION']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Bernabeu', 'Bernabeu']\n",
        "#     },\n",
        "#     '2335248900126': {\n",
        "#         'data': [[102, 103, 3, 'PERSON'], [181, 182, 6, 'PERSON']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Isco', 'Isco']\n",
        "#     },\n",
        "#     '2335248900156': {\n",
        "#         'data': [[126, 127, 4, 'PERSON'],\n",
        "#         [161, 162, 6, 'PERSON'],\n",
        "#         [168, 169, 6, 'PERSON'],\n",
        "#         [214, 215, 8, 'PERSON']],\n",
        "#             'real_count': 4,\n",
        "#                 'words': ['Zidane', 'Zidane', 'Zidane', 'Zidane']\n",
        "#     },\n",
        "#     '2335248900204': {\n",
        "#         'data': [[70, 71, 2, 'ORGANIZATION'],\n",
        "#         [99, 100, 3, 'ORGANIZATION'],\n",
        "#         [262, 263, 10, 'ORGANIZATION'],\n",
        "#         [386, 387, 16, 'ORGANIZATION'],\n",
        "#         [166, 167, 6, 'ORGANIZATION']],\n",
        "#             'real_count': 5,\n",
        "#                 'words': ['Betis', 'Betis', 'Betis', 'Betis', 'Real_Betis']\n",
        "#     },\n",
        "#     '2335248900217': {\n",
        "#         'data': [[177, 178, 6, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Asensio']\n",
        "#     },\n",
        "#     '2335248900239': {\n",
        "#         'data': [[197, 198, 7, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Luka_Modric']\n",
        "#     },\n",
        "#     '2335248900254': {\n",
        "#         'data': [[212, 213, 8, 'ORGANIZATION'],\n",
        "#         [384, 385, 16, 'ORGANIZATION']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Levante', 'Levante']\n",
        "#     },\n",
        "#     '2335248900285': {\n",
        "#         'data': [[89, 90, 2, 'PERSON'], [237, 238, 9, 'PERSON']],\n",
        "#             'real_count': 2,\n",
        "#                 'words': ['Ronaldo', 'Cristiano_Ronaldo']\n",
        "#     },\n",
        "#     '2335248900332': {\n",
        "#         'data': [[272, 273, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Marcelo']\n",
        "#     },\n",
        "#     '2335248900342': {\n",
        "#         'data': [[282, 284, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Theo Hernandez']\n",
        "#     },\n",
        "#     '2335248900345': {\n",
        "#         'data': [[285, 286, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Karim_Benzema']\n",
        "#     },\n",
        "#     '2335248900348': {\n",
        "#         'data': [[287, 288, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Mateo_Kovacic']\n",
        "#     },\n",
        "#     '2335248900351': {\n",
        "#         'data': [[289, 290, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Jesus_Vallejo']\n",
        "#     },\n",
        "#     '2335248900354': {\n",
        "#         'data': [[291, 292, 11, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Raphael_Varane']\n",
        "#     },\n",
        "#     '2335248900381': {\n",
        "#         'data': [[12, 14, 0, 'LOCATION'],\n",
        "#         [314, 316, 13, 'LOCATION'],\n",
        "#         [324, 326, 13, 'LOCATION']],\n",
        "#             'real_count': 3,\n",
        "#                 'words': ['Tây Ban_Nha', 'Tây Ban_Nha', 'Tây Ban_Nha']\n",
        "#     },\n",
        "#     '2335248900447': {\n",
        "#         'data': [[370, 371, 15, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Keylor_Navas']\n",
        "#     },\n",
        "#     '2335248900466': {\n",
        "#         'data': [[388, 389, 16, 'ORGANIZATION']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Real_Sociedad']\n",
        "#     },\n",
        "#     '2335248900475': {\n",
        "#         'data': [[3, 4, 0, 'ORGANIZATION'],\n",
        "#         [25, 26, 0, 'ORGANIZATION'],\n",
        "#         [38, 39, 1, 'ORGANIZATION'],\n",
        "#         [395, 396, 16, 'ORGANIZATION'],\n",
        "#         [63, 64, 1, 'ORGANIZATION'],\n",
        "#         [72, 73, 2, 'ORGANIZATION'],\n",
        "#         [143, 144, 5, 'ORGANIZATION'],\n",
        "#         [243, 244, 9, 'ORGANIZATION'],\n",
        "#         [279, 280, 11, 'ORGANIZATION'],\n",
        "#         [303, 304, 12, 'ORGANIZATION'],\n",
        "#         [338, 339, 13, 'ORGANIZATION']],\n",
        "#             'real_count': 11,\n",
        "#                 'words': ['Real_Madrid',\n",
        "#                     'Real_Madrid',\n",
        "#                     'Real_Madrid',\n",
        "#                     'Real_Madrid',\n",
        "#                     'Real',\n",
        "#                     'Real',\n",
        "#                     'Real',\n",
        "#                     'Real',\n",
        "#                     'Real',\n",
        "#                     'Real',\n",
        "#                     'Real']\n",
        "#     },\n",
        "#     '2335248900478': {\n",
        "#         'data': [[398, 400, 17, 'PERSON']],\n",
        "#             'real_count': 1,\n",
        "#                 'words': ['Hòa Lộc']\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# data_dict_rels = \\\n",
        "# {'AFFILIATION': [('2335248900475', '2335248900285')],\n",
        "#  'LOCATED': [('2335248900015', '2335248900381')],\n",
        "#  'PERSONAL - SOCIAL': [('2335248900156', '2335248900217')]}\n",
        "\n",
        "\n",
        "# \"\"\"\n",
        "#     1:PERSONAL - SOCIAL:2\tL2R\tNON-CROSS\t161-162\t177-178\t\n",
        "#     2335248900156\tZidane|Zidane|Zidane|Zidane\tPERSON\t126:161:168:214\t127:162:169:215\t4:6:6:8\t\n",
        "#     2335248900217\tAsensio\tPERSON\t177\t178\t6\n",
        "# \"\"\"\n",
        "\n",
        "# processes_ent_line_dict = \\\n",
        "# {'2335248900008': '2335248900008\\tBarcelona|Barcelona\\tORGANIZATION\\t5:320\\t'\n",
        "#                   '6:321\\t0:13',\n",
        "#  '2335248900015': '2335248900015\\tMarca\\tORGANIZATION\\t10\\t11\\t0',\n",
        "#  '2335248900061': '2335248900061\\tLionel_Messi|Messi\\tPERSON\\t46:52\\t47:53\\t'\n",
        "#                   '1:1',\n",
        "#  '2335248900117': '2335248900117\\tBernabeu|Bernabeu\\tLOCATION\\t94:112\\t95:113\\t'\n",
        "#                   '3:3',\n",
        "#  '2335248900126': '2335248900126\\tIsco|Isco\\tPERSON\\t102:181\\t103:182\\t3:6',\n",
        "#  '2335248900156': '2335248900156\\tZidane|Zidane|Zidane|Zidane\\tPERSON\\t'\n",
        "#                   '126:161:168:214\\t127:162:169:215\\t4:6:6:8',\n",
        "#  '2335248900204': '2335248900204\\tBetis|Betis|Betis|Betis|Real_Betis\\t'\n",
        "#                   'ORGANIZATION\\t70:99:262:386:166\\t71:100:263:387:167\\t'\n",
        "#                   '2:3:10:16:6',\n",
        "#  '2335248900217': '2335248900217\\tAsensio\\tPERSON\\t177\\t178\\t6',\n",
        "#  '2335248900239': '2335248900239\\tLuka_Modric\\tPERSON\\t197\\t198\\t7',\n",
        "#  '2335248900254': '2335248900254\\tLevante|Levante\\tORGANIZATION\\t212:384\\t'\n",
        "#                   '213:385\\t8:16',\n",
        "#  '2335248900285': '2335248900285\\tRonaldo|Cristiano_Ronaldo\\tPERSON\\t89:237\\t'\n",
        "#                   '90:238\\t2:9',\n",
        "#  '2335248900332': '2335248900332\\tMarcelo\\tPERSON\\t272\\t273\\t11',\n",
        "#  '2335248900342': '2335248900342\\tTheo Hernandez\\tPERSON\\t282\\t284\\t11',\n",
        "#  '2335248900345': '2335248900345\\tKarim_Benzema\\tPERSON\\t285\\t286\\t11',\n",
        "#  '2335248900348': '2335248900348\\tMateo_Kovacic\\tPERSON\\t287\\t288\\t11',\n",
        "#  '2335248900351': '2335248900351\\tJesus_Vallejo\\tPERSON\\t289\\t290\\t11',\n",
        "#  '2335248900354': '2335248900354\\tRaphael_Varane\\tPERSON\\t291\\t292\\t11',\n",
        "#  '2335248900381': '2335248900381\\tTây Ban_Nha|Tây Ban_Nha|Tây Ban_Nha\\t'\n",
        "#                   'LOCATION\\t12:314:324\\t14:316:326\\t0:13:13',\n",
        "#  '2335248900447': '2335248900447\\tKeylor_Navas\\tPERSON\\t370\\t371\\t15',\n",
        "#  '2335248900466': '2335248900466\\tReal_Sociedad\\tORGANIZATION\\t388\\t389\\t16',\n",
        "#  '2335248900475': '2335248900475\\t'\n",
        "#                   'Real_Madrid|Real_Madrid|Real_Madrid|Real_Madrid|Real|Real|Real|Real|Real|Real|Real\\t'\n",
        "#                   'ORGANIZATION\\t3:25:38:395:63:72:143:243:279:303:338\\t'\n",
        "#                   '4:26:39:396:64:73:144:244:280:304:339\\t'\n",
        "#                   '0:0:1:16:1:2:5:9:11:12:13',\n",
        "#  '2335248900478': '2335248900478\\tHòa Lộc\\tPERSON\\t398\\t400\\t17'}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rel_dict = {'AFFILIATION': [('2335200900510', '2335200900520'),\n",
        "#                  ('2335200900396', '2335200900396'),\n",
        "#                  ('2335200900192', '2335200900600'),\n",
        "#                  ('2335200900441', '2335200900600'),\n",
        "#                  ('2335200900396', '2335200900675')],\n",
        "#  'LOCATED': [('2335200900014', '2335200900170'),\n",
        "#              ('2335200900276', '2335200900283')]}\n",
        "\n",
        "# set_ent_has_rel = set(i for k,v in rel_dict.items() for item in v for i in item)\n",
        "# print(set_ent_has_rel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# d_dict = \\\n",
        "# {\n",
        "#     \"2335248900008\": {\n",
        "#         \"data\": [\n",
        "#             [\n",
        "#                 5,\n",
        "#                 6,\n",
        "#                 0,\n",
        "#                 \"ORGANIZATION\"\n",
        "#             ],\n",
        "#             [\n",
        "#                 320,\n",
        "#                 321,\n",
        "#                 13,\n",
        "#                 \"ORGANIZATION\"\n",
        "#             ]\n",
        "#         ],\n",
        "#         \"real_count\": 2,\n",
        "#         \"words\": [\n",
        "#             \"Barcelona\",\n",
        "#             \"Barcelona\"\n",
        "#         ]\n",
        "#     },\n",
        "#     \"2335248900015\": {\n",
        "#         \"data\": [\n",
        "#             [\n",
        "#                 10,\n",
        "#                 11,\n",
        "#                 0,\n",
        "#                 \"ORGANIZATION\"\n",
        "#             ]\n",
        "#         ],\n",
        "#         \"real_count\": 1,\n",
        "#         \"words\": [\n",
        "#             \"Marca\"\n",
        "#         ]\n",
        "#     },\n",
        "#     \"2335248900061\": {\n",
        "#         \"data\": [\n",
        "#             [\n",
        "#                 46,\n",
        "#                 47,\n",
        "#                 1,\n",
        "#                 \"PERSON\"\n",
        "#             ],\n",
        "#             [\n",
        "#                 52,\n",
        "#                 53,\n",
        "#                 1,\n",
        "#                 \"PERSON\"\n",
        "#             ]\n",
        "#         ],\n",
        "#         \"real_count\": 2,\n",
        "#         \"words\": [\n",
        "#             \"Lionel_Messi\",\n",
        "#             \"Messi\"\n",
        "#         ]\n",
        "#     }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "        \n",
        "# def clear_file(full_path_to_files_list):\n",
        "#     for _file in full_path_to_files_list:\n",
        "#       with open(_file,'w') as out:\n",
        "#         out.write(f'')\n",
        "\n",
        "# from pprint import pprint\n",
        "# OUT_error_not_found_ent_in_msg_FOLDER_path = \\\n",
        "#     \"/Users/n2t2k/Documents/Studying/Master/Thesis/InProgress/Coding/ORIGIN_RUN_ALL_edge-oriented-graph-master-studying/dataProcessingOfficialCleaned/dev_processed/split_sentence_underthesea/error/error_not_found_ent_in_msg\"\n",
        "# # clear_file([f\"{OUT_error_not_found_ent_in_msg_FOLDER_path}/json.json\"])\n",
        "\n",
        "# import json\n",
        "\n",
        "# j_path = f\"{OUT_error_not_found_ent_in_msg_FOLDER_path}/json.json\"\n",
        "\n",
        "\n",
        "\n",
        "# def update_json_to_json_file(d_dict, j_path):\n",
        "#     json_object = json.load(\n",
        "#                 open(j_path)\n",
        "#             )\n",
        "#     print(json_object)\n",
        "#     d_all = {}\n",
        "#     d_all.update(json_object)\n",
        "#     d_all.update(d_dict)\n",
        "#     print(d_all)\n",
        "#     with open(j_path, 'w') as f:\n",
        "#         json.dump(d_all, f)\n",
        "\n",
        "# update_json_to_json_file(d_dict, j_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rl []\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def find_word_pos_in_set(s, w_find):\n",
        "    return [w.start() for w in re.finditer(w_find, s)]\n",
        "\n",
        "def find_related_word_in_sent(sent, txt):\n",
        "    \"\"\"\n",
        "        find word related to the ent in sentence\n",
        "        IN: ent, sent\n",
        "        OUT list [related, replace_related_expected_word]\n",
        "    \"\"\"\n",
        "    sent_split = sent.replace(\"_\",\" \")\n",
        "    txt_split = txt.replace(\"_\",\" \")\n",
        "    txt_len = len(txt)\n",
        "    start_pos = find_word_pos_in_set(sent_split, txt_split[0])\n",
        "    list_word_in_sent = []\n",
        "\n",
        "    for p in start_pos:\n",
        "        # try:\n",
        "        if 1:\n",
        "            rel_word_in_sent_expect = sent_split[p:p+txt_len] \n",
        "            if rel_word_in_sent_expect == txt_split:\n",
        "                related_word = sent[p-1:p+txt_len+1]\n",
        "                related_word_replace = related_word.replace(\"_\",\" \").replace(txt_split, txt_split.replace(\" \",\"_\"))\n",
        "                list_word_in_sent.append([related_word,related_word_replace])\n",
        "            # elif \".|\" in rel_word_in_sent_expect:\n",
        "            #     rel_word_in_sent_expect = sent_split[p:p+txt_len+1] \n",
        "            #     print(txt_split)\n",
        "            #     print(rel_word_in_sent_expect)\n",
        "            #     short_expect = rel_word_in_sent_expect.replace(\".|\",\"\").replace(\".\",\"\").replace(\" \",\"\")\n",
        "            #     short_txt = txt_split.replace(\".\",\"\").replace(\" \",\"\")\n",
        "            #     print(\"short_expect \", short_expect, len(short_expect))\n",
        "            #     print(\"short_txt \", short_txt, len(short_txt))\n",
        "            #     print(short_expect==short_txt)\n",
        "            #     if short_expect==short_txt:\n",
        "            #         print(txt_split)\n",
        "            #         print(rel_word_in_sent_expect)\n",
        "            #         related_word = sent[p-1:p+len(rel_word_in_sent_expect)]\n",
        "            #         related_word_replace = related_word.replace(\"_\",\" \").replace(txt_split, txt_split.replace(\" \",\"_\"))\n",
        "            #         list_word_in_sent.append([related_word,related_word_replace])\n",
        "\n",
        "        # except:\n",
        "        #     pass\n",
        "    return list_word_in_sent\n",
        "\n",
        "# sent = \"Oceanbank_Phòng giao dịch Đông_Đô_ ), Nguyễn_Thị_Loan Phòng guyễn_Thị_Loan \"\n",
        "# txt = \"Phòng giao_dịch Đông_Đô\"\n",
        "\n",
        "\n",
        "# sent = \"nhà và Đinh_Thanh Trung_thực_hiện\"\n",
        "# txt = \"và Đinh_Thanh Trung\"\n",
        "\n",
        "sent = \" lục_chiến Robert .|E. Cashman_ đã đề_x\"\n",
        "txt = \"Robert. E. Cashman\"\n",
        "\n",
        "rl = find_related_word_in_sent(sent, txt)\n",
        "print(\"rl\", rl)\n",
        "# for r in rl:\n",
        "#     r,p = r\n",
        "#     print(\">> \",r,p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
